{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import evaluate, print_perf\n",
    "from surprise import BaselineOnly\n",
    "from surprise import GridSearch\n",
    "from surprise import accuracy\n",
    "from surprise import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv', header=None)\n",
    "df.columns = ['userId', 'itemId', 'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the full dataset.\n",
    "reader = Reader(rating_scale=(0.5,5))\n",
    "data = Dataset.load_from_df(df[['userId', 'itemId', 'rating']], reader)\n",
    "raw_ratings = data.raw_ratings\n",
    "\n",
    "# shuffle ratings\n",
    "random.shuffle(raw_ratings)\n",
    "\n",
    "# A = 80% of the data, B = 20% of the data\n",
    "threshold = int(.8 * len(raw_ratings))\n",
    "A_raw_ratings = raw_ratings[:threshold]\n",
    "B_raw_ratings = raw_ratings[threshold:]\n",
    "\n",
    "data.raw_ratings = A_raw_ratings\n",
    "data.split(n_folds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search...\n",
      "[{'bsl_options': {'n_epochs': 20, 'reg_i': 5, 'method': 'als', 'reg_u': 5}}, {'bsl_options': {'n_epochs': 50, 'reg_i': 5, 'method': 'als', 'reg_u': 5}}, {'bsl_options': {'n_epochs': 100, 'reg_i': 5, 'method': 'als', 'reg_u': 5}}, {'bsl_options': {'n_epochs': 20, 'reg_i': 10, 'method': 'als', 'reg_u': 5}}, {'bsl_options': {'n_epochs': 50, 'reg_i': 10, 'method': 'als', 'reg_u': 5}}, {'bsl_options': {'n_epochs': 100, 'reg_i': 10, 'method': 'als', 'reg_u': 5}}, {'bsl_options': {'n_epochs': 20, 'reg_i': 100, 'method': 'als', 'reg_u': 5}}, {'bsl_options': {'n_epochs': 50, 'reg_i': 100, 'method': 'als', 'reg_u': 5}}, {'bsl_options': {'n_epochs': 100, 'reg_i': 100, 'method': 'als', 'reg_u': 5}}, {'bsl_options': {'n_epochs': 20, 'reg_i': 5, 'method': 'als', 'reg_u': 15}}, {'bsl_options': {'n_epochs': 50, 'reg_i': 5, 'method': 'als', 'reg_u': 15}}, {'bsl_options': {'n_epochs': 100, 'reg_i': 5, 'method': 'als', 'reg_u': 15}}, {'bsl_options': {'n_epochs': 20, 'reg_i': 10, 'method': 'als', 'reg_u': 15}}, {'bsl_options': {'n_epochs': 50, 'reg_i': 10, 'method': 'als', 'reg_u': 15}}, {'bsl_options': {'n_epochs': 100, 'reg_i': 10, 'method': 'als', 'reg_u': 15}}, {'bsl_options': {'n_epochs': 20, 'reg_i': 100, 'method': 'als', 'reg_u': 15}}, {'bsl_options': {'n_epochs': 50, 'reg_i': 100, 'method': 'als', 'reg_u': 15}}, {'bsl_options': {'n_epochs': 100, 'reg_i': 100, 'method': 'als', 'reg_u': 15}}, {'bsl_options': {'n_epochs': 20, 'reg_i': 5, 'method': 'als', 'reg_u': 100}}, {'bsl_options': {'n_epochs': 50, 'reg_i': 5, 'method': 'als', 'reg_u': 100}}, {'bsl_options': {'n_epochs': 100, 'reg_i': 5, 'method': 'als', 'reg_u': 100}}, {'bsl_options': {'n_epochs': 20, 'reg_i': 10, 'method': 'als', 'reg_u': 100}}, {'bsl_options': {'n_epochs': 50, 'reg_i': 10, 'method': 'als', 'reg_u': 100}}, {'bsl_options': {'n_epochs': 100, 'reg_i': 10, 'method': 'als', 'reg_u': 100}}, {'bsl_options': {'n_epochs': 20, 'reg_i': 100, 'method': 'als', 'reg_u': 100}}, {'bsl_options': {'n_epochs': 50, 'reg_i': 100, 'method': 'als', 'reg_u': 100}}, {'bsl_options': {'n_epochs': 100, 'reg_i': 100, 'method': 'als', 'reg_u': 100}}]\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    }
   ],
   "source": [
    "# Select your best algo with grid search.\n",
    "print('Grid Search...')\n",
    "param_grid = {'bsl_options': {'method': ['als'],\n",
    "                              'n_epochs': [20, 50, 100],\n",
    "                              'reg_u': [5, 15, 100],\n",
    "                              'reg_i': [5, 10, 100]}\n",
    "             }\n",
    "grid_search = GridSearch(BaselineOnly, param_grid, measures=['RMSE'], verbose=0)\n",
    "grid_search.evaluate(data)\n",
    "\n",
    "algo = grid_search.best_estimator['RMSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(grid_search.cv_results, open(\"baseline_result\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n"
     ]
    }
   ],
   "source": [
    "# retrain on the whole set A\n",
    "trainset = data.build_full_trainset()\n",
    "algo.train(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84698115006857355"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute biased accuracy on A - predictions of the 'original' algorithm.\n",
    "predictions = algo.test(trainset.build_testset())\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8593878321944346"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute unbiased accuracy on B - unseen testset\n",
    "testset = data.construct_testset(B_raw_ratings)  # testset is now the set B\n",
    "predictions = algo.test(testset)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dump algorithm \n",
    "file_name = os.path.expanduser('dump_BaselineAlgo')\n",
    "dump.dump(file_name, predictions, algo=algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload algorithm\n",
    "_, algo = dump.load('dump_BaselineAlgo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on the final_train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_train.csv', header=None)\n",
    "df.columns = ['userId', 'itemId', 'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the full dataset.\n",
    "reader = Reader(rating_scale=(0.5,5))\n",
    "data = Dataset.load_from_df(df[['userId', 'itemId', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Retrieve the trainset.\n",
    "trainset = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n"
     ]
    }
   ],
   "source": [
    "algo.train(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump algorithm \n",
    "file_name = os.path.expanduser('dump_finalBaselineAlgo')\n",
    "dump.dump(file_name, algo=algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload algorithm\n",
    "_, algo = dump.load('dump_finalBaselineAlgo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predicted value from the trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_train.csv', header=None)\n",
    "df.columns = ['userId', 'itemId', 'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the full dataset.\n",
    "reader = Reader(rating_scale=(0.5,5))\n",
    "data = Dataset.load_from_df(df[['userId', 'itemId', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_ratings = data.raw_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataset = data.construct_testset(raw_ratings)  \n",
    "predictions = algo.test(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84957029131673034"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.6521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.65212994575808203"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('prediction_final_train', 'w')\n",
    "for l in predictions:\n",
    "    f.write(str(l.uid)+','+str(l.iid)+','+str(round(l.est,3))+'\\n')\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### map inner id to raw id for user and item bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw2inner_id_items_dict = trainset._raw2inner_id_items\n",
    "raw2inner_id_users_dict = trainset._raw2inner_id_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_raw2inner_id_items_dict = {}\n",
    "for (k, v) in raw2inner_id_items_dict.items():\n",
    "    new_raw2inner_id_items_dict[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_raw2inner_id_users_dict = {}\n",
    "for (k, v) in raw2inner_id_users_dict.items():\n",
    "    new_raw2inner_id_users_dict[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_to_raw_id(l, d):\n",
    "    keys = d.values()\n",
    "    values = l\n",
    "    new_dict = dict(zip(keys, values))\n",
    "    return zip(keys, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bi = algo.bi\n",
    "rawid_bi = map_to_raw_id(bi, new_raw2inner_id_items_dict)\n",
    "rawid_bi.sort()\n",
    "pickle.dump(rawid_bi, open('final_rawidItemBias', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "bu = algo.bu\n",
    "rawid_bu = map_to_raw_id(bu, new_raw2inner_id_users_dict)\n",
    "rawid_bu.sort()\n",
    "pickle.dump(rawid_bu, open('final_rawidUserBias', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_test.csv', header=None)\n",
    "df.columns = ['userId', 'itemId', 'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pred'] = df.apply(lambda x: algo.predict(x[0],x[1])[3], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>itemId</th>\n",
       "      <th>rating</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>1512</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.390350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>1425</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.939926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>2371</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.612307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>1107</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.571033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>2532</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.942190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  itemId  rating      pred\n",
       "0      51    1512     3.0  2.390350\n",
       "1      51    1425     2.0  2.939926\n",
       "2      51    2371     3.0  3.612307\n",
       "3      51    1107     3.0  3.571033\n",
       "4      51    2532     4.0  2.942190"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('test_prediction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE and MAE on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the full dataset.\n",
    "reader = Reader(rating_scale=(0.5,5))\n",
    "data = Dataset.load_from_df(df[['userId', 'itemId', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_ratings = data.raw_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = testdata.construct_testset(raw_ratings)\n",
    "predictions = algo.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85884422741116728"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.6600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.66000707442924811"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
